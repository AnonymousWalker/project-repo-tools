# -*- coding: utf-8 -*-
# In many Markdown files, the translators alter the number of hash marks, not realizing
# that by doing so they break the Markdown heading scheme.
# For example, the header jump from level 1 with level 4 with no level 2 and 3 in between.
# Or some files start out with a level 2 header.
# This program intends to eliminate the jumps in heading levels by applying some
# informed guessing as to what the levels should have been. The algorithm is not perfect.
# The goal is to reduce the Errors and Warnings generated by the Door43 page builds
# while restoring the heading levels closer to their intended order.
# The program promotes the first heading found to a level 1,
#   and normalizes the subsequent heading levels.
# The success of the algorithm is affected by the consistency of the translator in assigning
# the original heading levels.
# All the above program behavior is optional. Set suppress1 if you don't want it.
#
# Backs up the files being modified.
# Outputs files of the same name in the same location.
#
# Additional behavior:
#   Converts malformed heading marks "# #"
#   Removes blank lines between markdown list items.
#   Assures blank links before and after header lines.
#   Leading spaces before the asterisk are also removed.
#   Assures newline at the end of the file.
#
# Also expands incomplete references to tA articles.
# For example, expands Vidi: figs_metaphor to Vidi: [[rc://*/ta/man/translate/figs-metaphor]]

import re       # regular expression module
import io
import os
import string
import sys
from filecmp import cmp
import substitutions    ################ Update this module before running script ##################

# Globals
source_dir = r"C:\DCS\Telugu\te_ta.STR"
language_code = 'te'
resource_type = 'ta'

suppress1 = False       # Suppress hash mark cleanup
suppress2 = True       # Suppress stdout informational messages 
if resource_type == 'ta':
    suppress1 = True
#if language_code in {'ne'}:
#    suppress2 = True

nChanged = 0
max_files = 1111
filename_re = re.compile(r'\d+\.md$')  # This can change for different collections of .md files
if resource_type in {'tw','ta'}:
    filename_re = re.compile(r'.*\.md$')
hash_re = re.compile(r' *(#+) +', flags=re.UNICODE)
asterisk_re = re.compile('(\n *\* .*)\n(\n *\* )', flags=re.UNICODE)    # two list items with blank line between

keystring = []      # These strings are searched to determine files that are candidates for change
keystring.append( re.compile(r'figs_', flags=re.UNICODE) )
keystring.append( re.compile(r'translate_', flags=re.UNICODE) )
keystring.append( re.compile(r'writing_', flags=re.UNICODE) )
keystring.append( re.compile(r'guidelines_', flags=re.UNICODE) )
keystring.append( re.compile(r'bita_', flags=re.UNICODE) )


def shortname(longpath):
    shortname = longpath
    if source_dir in longpath:
        shortname = longpath[len(source_dir)+1:]
    return shortname

# Converts the text a whole file at a time.
# Removes blank lines between list items.
def fixLists(alltext):
    # Multiple replacements per file
    found = asterisk_re.search(alltext)
    while found:
        alltext = alltext[0:found.start()] + found.group(1) + found.group(2) + alltext[found.end():]
        found = asterisk_re.search(alltext)
    return alltext

# Calculates and returns the new header level.
# Updates the truelevel list.
def shuffle(truelevel, nmarks, currlevel):
    newlevel = currlevel
    if nmarks > currlevel and truelevel[nmarks] > currlevel:
        newlevel = currlevel + 1
    elif truelevel[nmarks] < currlevel:
        newlevel = truelevel[nmarks]
    
    # Adjust the array
    while nmarks > 1 and truelevel[nmarks] > newlevel:
        truelevel[nmarks] = newlevel
        nmarks -= 1
    return newlevel    

# Normalizes markdown heading levels.
# Removes training blanks from header lines.
def fixHeadingLevels(str):
    nChanges = 0
    text = ""
    lines = str.splitlines()
    currlevel = 0
    truelevel = [0,1,2,3,4,5,6,7,8,9]
        # each position in the array represents the calculate true header level for that number of hash marks.
        # To start, the number of hash marks is assumed to be the true level.
        # This array is modified by the shuffle() function.

    for line in lines:
        header = hash_re.match(line, 0)
        if header:
            nmarks = len(header.group(1))
            newlevel = shuffle(truelevel, nmarks, currlevel)
            if newlevel != nmarks:
                line = '#' * newlevel + ' ' + line[header.end():]
                nChanges += 1
            currlevel = newlevel
        text += line.rstrip() + '\n'
    return text

inlinekey = []      # These are the strings that are actually replaced
inlinekey.append( re.compile(r'[\:\( ]figs_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'[\:\( ]translate_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'[\:\( ]writing_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'[\:\( ]guidelines_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'[\:\( ]bita_(\w*)', flags=re.UNICODE) )
newstring = []
newstring.append( 'figs-' )
newstring.append( 'translate-' )
newstring.append( 'writing-' )
newstring.append( 'guidelines-' )
newstring.append( 'bita-' )

# Replaces primitive tA links (those that match something in inlinekey[])
def fixTaLinks(str):
    text = ""
    count = 0
    lines = str.splitlines()
    for line in lines:
        count += 1
        for i in range(len(inlinekey)):
            good_ref = ' [[rc://*/ta/man/translate/' + newstring[i]
            sub = inlinekey[i].search(line)
            while sub:
                line = line[0:sub.start()] + good_ref + sub.group(1) + ']]' + line[sub.end():]
                sub = inlinekey[i].search(line)
        text += line + '\n'
    return text
    
notelink_re = re.compile(r'(rc://[ \*\w\-]+/tn/help/)(\w\w\w/\d+)/(\d+)', flags=re.UNICODE)

# Note links currently are not rendered on live site as links.
def fixTnLinks(str):
    newstr = ""
    notelink = notelink_re.search(str)     # rc://.../tn/help/...
    while notelink:
        chunkmd = notelink.group(3)
        if len(chunkmd) == 1:
            chunkmd = "0" + chunkmd
        if notelink.group(2).startswith("psa") and len(chunkmd) == 2:
            chunkmd = "0" + chunkmd
        newstr += str[0:notelink.start()] + notelink.group(1) + notelink.group(2) + "/" + chunkmd
        str = str[notelink.end():]
        notelink = notelink_re.search(str)
    newstr += str
    return newstr

blanks_re = re.compile('[\n \t]+')     # multiple newlines/ white space at beginning of string
hashblanks_re = re.compile('#  +')      # multiple spaces after hash mark
endblank_re = re.compile('[\n \t][\n \t]+\Z')     # multiple newlines/ white space at end of string
jams_re = re.compile(r'^#+[^ \t#]', re.UNICODE+re.MULTILINE)    # hash(es) at beginning of line not followed by space
#jams2_re = re.compile(r'\n\*[^ \t\*]', re.UNICODE)   # single asterisk at beginning of line not follow by space

# Does some simple cleanup operations before starting the heavy conversions.
def preliminary_cleanup(text):
    if resource_type != 'ta':
        if found := blanks_re.match(text):
            text = text[found.end():] + '\n'    # remove blanks at beginning of string
    if found := endblank_re.search(text):
        text = text[0:found.start()] + '\n'     # remove blank lines at end of string
    if not text.endswith("\n"):
        text += "\n"
    text = text.replace("# #", "##")
    found = jams_re.search(text)
    while found:
        text = text[:found.end()-1] + ' ' + text[found.end()-1:]    # add space after mark at beginning of lines
        found = jams_re.search(text)
#    found = jams2_re.search(text)      # Removed 11/16/20 because sometimes the no-space is intended (for italics)
#    while found:
#        text = text[:found.end()-1] + ' ' + text[found.end()-1:]
#        found = jams2_re.search(text)
    text = re.sub(hashblanks_re, "# ", text)
    return text

# Applies the substitutions found in substitutions.py, plus one that is language specific
def substitution(text):
    substitutions.subs.append(	("rc://" + language_code + "/", "rc://*/") )
    for pair in substitutions.subs:
        text = text.replace(pair[0], pair[1])
    return text

# Reads the entire file as a string and converts it.
def convertWholeFile(source, target):
    global suppress1
    fixHeadings = not suppress1
    input = io.open(source, "tr", encoding="utf-8-sig")
    text = input.read()
    input.close()

    origtext = text
    text = preliminary_cleanup(text)
    text = substitution(text)
    if not text.startswith("# "):
        if not suppress2:
            sys.stdout.write(shortname(source) + " does not begin with level 1 heading, so no headings will be touched.\n")
        fixHeadings = False

    # Do the hash level fixes and TA references
    if fixHeadings and "## " in text:
        text = fixHeadingLevels(text)

    # I took out this code 11/16/20 since it appears that the markdown dialect that we support allows blank
    # lines between list items.
    #    if asterisk_re.search(text) and not suppress2:
    #        text = fixLists(text)

    # Expand the TA links
    convertme = False
    for key in keystring:
        if key.search(text):
            convertme = True
            break
    if convertme:
        text = fixTaLinks(text)
    text = fixTnLinks(text)
    
    changed = (text != origtext)
    if changed:
        if len(text) < 3:
            sys.stderr.write("Empty or almost empty file: " + shortname(source) + '\n')
        elif len(origtext) > 20 and len(text) < len(origtext) * 0.95:
            sys.stderr.write("Error processing (>5% size reduction): " + shortname(source) + '\n')
            changed = False
    if changed:
        output = io.open(target, "tw", encoding='utf-8', newline='\n')
        output.write(text)
        output.close()

# Adds blank lines where needed before and after heading lines
def convertByLine(source, target):
    input = io.open(source, "tr", 1, encoding="utf-8-sig")
    lines = input.readlines()
    input.close()

    BLANK = 0       # blank line or top of file
    HEADER = 1
    TEXT = 2
    linetype = BLANK
    output = io.open(target, "tw", buffering=1, encoding='utf-8', newline='\n')
    for line in lines:
        prevlinetype = linetype
        if line[0] == '#':
            linetype = HEADER
        elif len(line.strip()) == 0:
            linetype = BLANK
        else:
            linetype = TEXT
        if (linetype == HEADER and prevlinetype != BLANK) or (linetype == TEXT and prevlinetype == HEADER):
            output.write('\n')
        output.write(line)
    output.close

# Compares content of two files, but use filecmp.cmp() instead
#def file_changed(tmppath, path):
#    file = io.open(tmppath, "tr", encoding="utf-8-sig")
#    origtext = file.read()
#    file.close()
#    file = io.open(path, "tr", encoding="utf-8-sig")
#    newtext = file.read()
#    file.close()
#    return (newtext != origtext)

def convertFile(path):
    tmppath = path + ".tmp"
    convertWholeFile(path, tmppath)
    if not os.path.isfile(tmppath):
        tmppath = path
    tmppath2 = path + ".tmp2"
    convertByLine(tmppath, tmppath2)
#    changed = file_changed(tmppath2, path)
    changed = not cmp(tmppath2, path, shallow=False)
    if changed:
        global nChanged
        nChanged += 1
        sys.stdout.write("Converted " + shortname(path) + "\n")
        bakpath = path + ".orig"
        if not os.path.isfile(bakpath):
            os.rename(path, bakpath)
        else:
            os.remove(path)
        os.rename(tmppath2, path)
    if not changed:
        os.remove(tmppath2)
    if tmppath != path:
        os.remove(tmppath)

# Recursive routine to convert all files under the specified folder
def convertFolder(folder):
    global nChanged
    global max_files
    if nChanged >= max_files:
        return
    for entry in os.listdir(folder):
        path = os.path.join(folder, entry)
        if os.path.isdir(path) and entry[0] != '.':
            convertFolder(path)
        elif filename_re.match(entry) and not entry.startswith("LICENSE"):
            convertFile(path)
        if nChanged >= max_files:
            break
    sys.stdout.flush()

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] != 'hard-coded-path':
        source_dir = sys.argv[1]

    if source_dir and os.path.isdir(source_dir):
        convertFolder(source_dir)
        sys.stdout.write("Done. Changed " + str(nChanged) + " files.\n")
    elif os.path.isfile(source_dir):
        path = source_dir
        source_dir = os.path.dirname(path)
        convertFile(path)
    else:
        sys.stderr.write("Usage: python md_cleanup.py <folder>\n  Use . for current folder or hard code the path.\n")
