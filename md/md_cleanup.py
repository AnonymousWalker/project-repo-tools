# -*- coding: utf-8 -*-
# In many Markdown files, the translators alter the number of hash marks, not realizing
# that by doing so they break the Markdown heading scheme.
# For example, the header jump from level 1 with level 4 with no level 2 and 3 in between.
# Or some files start out with a level 2 header.
# This program intends to eliminate the jumps in heading levels by applying some
# informed guessing as to what the levels should have been. The algorithm is not perfect.
# The goal is to reduce the Errors and Warnings generated by the Door43 page builds
# while restoring the heading levels closer to their intended order.
# Correct operation of the algorithm depends on the consistency of the translator in assigning
# heading levels.
#
# This script was written for .md files.
# As currently implemented, it enforces a level 1 heading to start the file.
# Backs up the files being modified.
# Outputs files of the same name in the same location.
#
# This program also removes blank lines between markdown list items.
# Leading spaces before the asterisk are also removed.
# List items start with an asterisk followed by a space.
#
# Also expands incomplete references to tA articles.
# For example, expands Vidi: figs_metaphor to Vidi: [[rc://*/ta/man/translate/figs-metaphor]]


import re       # regular expression module
import io
import os
#import shutil
#import codecs
import string
import sys

# Globals
nProcessed = 0
max_files = 1111
sourceDir = r"E:\DCS\Croatian\hr_tn\2sa"
suppress1 = True       # Suppress hash mark cleanup
suppress2 = True       # Suppress list cleanup

filename_re = re.compile(r'.*\.md$')
hash_re = re.compile(r' *(#+) +', flags=re.UNICODE)
asterisk_re = re.compile('(\n *\* .*)\n(\n *\* )', flags=re.UNICODE)

keystring = []
keystring.append( re.compile(r'figs_', flags=re.UNICODE) )
keystring.append( re.compile(r'translate_', flags=re.UNICODE) )
keystring.append( re.compile(r'writing_', flags=re.UNICODE) )
keystring.append( re.compile(r'guidelines_', flags=re.UNICODE) )
keystring.append( re.compile(r'bita_', flags=re.UNICODE) )
inlinekey = []
inlinekey.append( re.compile(r'figs_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'translate_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'writing_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'guidelines_(\w*)', flags=re.UNICODE) )
inlinekey.append( re.compile(r'bita_(\w*)', flags=re.UNICODE) )
# Strings to replace with
newstring = []
newstring.append( 'figs-' )
newstring.append( 'translate-' )
newstring.append( 'writing-' )
newstring.append( 'guidelines-' )
newstring.append( 'bita-' )


def shortname(longpath):
    shortname = longpath
    if sourceDir in longpath:
        shortname = longpath[len(sourceDir)+1:]
    return shortname

# Converts the text a whole file at a time.
# Removes blank lines between list items.
def fixLists(path):
    input = io.open(path, "tr", encoding="utf-8-sig")
    alltext = input.read()
    input.close()
    tmppath = path + ".tmp"
    output = io.open(tmppath, "tw", buffering=1, encoding='utf-8', newline='\n')
    
    # Multiple replacements per file
    while found := asterisk_re.search(alltext):
        output.write( alltext[0:found.start()] + found.group(1) )
        alltext = found.group(2) + alltext[found.end():]
        found = asterisk_re.search(alltext)
    output.write(alltext)
    output.close()
    sys.stdout.write("Fixed " + shortname(mdpath) + "\n")

    bakpath = mdpath + ".orig"
    if not os.path.isfile(bakpath):
        os.rename(path, bakpath)
    os.rename(tmppath, path)

# Calculates and returns the new header level.
# Updates the truelevel list.
def shuffle(truelevel, nmarks, currlevel):
    newlevel = currlevel
    if nmarks > currlevel and truelevel[nmarks] > currlevel:
        newlevel = currlevel + 1
    elif truelevel[nmarks] < currlevel:
        newlevel = truelevel[nmarks]
    
    # Adjust the array
    while nmarks > 1 and truelevel[nmarks] > newlevel:
        truelevel[nmarks] = newlevel
        nmarks -= 1
    return newlevel    

# Normalizes markdown heading levels.
# Removes training blanks from header lines.
def fixHeadings(path):
    nChanges = 0
    input = io.open(path, "tr", 1, encoding="utf-8-sig")
    lines = input.readlines()
    input.close()
    tmppath = path + ".tmp"
    output = io.open(tmppath, "tw", buffering=1, encoding='utf-8', newline='\n')
    
    currlevel = 0
    truelevel = [0,1,2,3,4,5,6,7,8,9]
        # each position in the array represents the calculate true header level for that number of hash marks.
        # To start, the number of hash marks is assumed to be the true level.
        # This array is modified by the shuffle() function.

    for line in lines:
        header = hash_re.match(line, 0)
        if header:
            nmarks = len(header.group(1))
            newlevel = shuffle(truelevel, nmarks, currlevel)
            if newlevel != nmarks:
                line = '#' * newlevel + ' ' + line[header.end():]
                nChanges += 1
            currlevel = newlevel
        output.write(line.rstrip() + '\n')
    output.close()

    if nChanges == 0:
        sys.stdout.write("Restoring " + shortname(path) + '\n')
        os.remove(tmppath)
    else:
        bakpath = path + ".orig"
        if not os.path.isfile(bakpath):
            os.rename(path, bakpath)
        os.rename(tmppath, path)

# Detects whether file contains the string we are looking for.
# If there is a match, calls doConvert to do the conversion.
def fixTaLinks(path):
    input = io.open(path, "tr", 1, encoding="utf-8-sig")
    lines = input.readlines()
    input.close()
    bakpath = path + ".orig"
    if not os.path.isfile(bakpath):
        os.rename(path, bakpath)
    count = 0
    output = io.open(path, "tw", buffering=1, encoding='utf-8', newline='\n')
    for line in lines:
        count += 1
        for i in range(len(inlinekey)):
            good_ref = '[[rc://*/ta/man/translate/' + newstring[i]
            sub = inlinekey[i].search(line)
            while sub:
                line = line[0:sub.start()] + good_ref + sub.group(1) + ']]' + line[sub.end():]
                sub = inlinekey[i].search(line)
        output.write(line)
    output.close

def convertFile(path):
    global nProcessed
    input = io.open(path, "tr", 1, encoding="utf-8-sig")
    text = input.read()
    input.close()
    
    # Do the hash level fixes and TA references
    if "## " in text and not suppress1:
        fixHeadings(path)
        nProcessed += 1
    # Do the list style fixes
    if asterisk_re.search(text) and not suppress2:
        fixLists(path)
        nProcessed += 1
    # Expand the TA links
    convertme = False
    for key in keystring:
        if key.search(text):
            convertme = True
            break
    if convertme:
        fixTaLinks(path)    
        nProcessed += 1

# Recursive routine to convert all files under the specified folder
def convertFolder(folder):
    global nProcessed
    global max_files
    if nProcessed >= max_files:
        return
    sys.stdout.write("Processing " + shortname(folder) + '\n')
    sys.stdout.flush()
    for entry in os.listdir(folder):
        path = os.path.join(folder, entry)
        if os.path.isdir(path) and entry[0] != '.':
            convertFolder(path)
        elif filename_re.match(entry):
            convertFile(path)
        if nProcessed >= max_files:
            break


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] != 'hard-coded-path':
        sourceDir = sys.argv[1]

    if sourceDir and os.path.isdir(sourceDir):
        convertFolder(sourceDir)
        sys.stdout.write("Done. " + str(nProcessed) + " files needed attention.\n")
    elif os.path.isfile(sourceDir):
        path = sourceDir
        sourceDir = os.path.dirname(path)
        convertFile(path)
    else:
        sys.stderr.write("Usage: python md_cleanup.py <folder>\n  Use . for current folder or hard code the path.\n")
