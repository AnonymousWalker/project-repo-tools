#!/usr/bin/env python3
# -*- coding: utf8 -*-
#
#  Copyright (c) 2019 unfoldingWord
#  http://creativecommons.org/licenses/MIT/
#  See LICENSE file for details.
#
#  Contributors:
#  Richard Mahn <rich.mahn@unfoldingword.org>

"""
Class for any resource PDF converter
"""
import os
import re
import logging
import tempfile
import markdown2
import shutil
import subprocess
import string
import requests
import sys
import argparse
from typing import List, Type
from glob import glob
from bs4 import BeautifulSoup
from abc import abstractmethod
from weasyprint import HTML, LOGGER
from .resource import Resource, Resources
from ..general_tools.file_utils import write_file, load_json_object

DEFAULT_LANG_CODE = 'en'
DEFAULT_OWNER = 'unfoldingWord'
DEFAULT_TAG = 'master'
LANGUAGE_FILES = {
    'fr': 'French-fr_FR.json',
    'en': 'English-en_US.json'
}


class PdfConverter(object):

    def __init__(self, resources: Resources, project_id=None, working_dir=None, output_dir=None,
                 lang_code=DEFAULT_LANG_CODE, regenerate=False, logger=None):
        self.resources = resources
        self.main_resource = self.resources.main
        self.project_id = project_id
        self.working_dir = working_dir
        self.output_dir = output_dir
        self.lang_code = lang_code
        self.regenerate = regenerate
        self.logger = logger

        self.bad_links = {}
        self.resource_data = {}
        self.rc_references = {}
        self.rc_lookup = {}
        self.title = None
        self.project_title = None
        self.version = None
        self.file_id = None
        self.html_dir = None
        self.save_dir = None
        self.html_file = None
        self.pdf_file = None
        self.generation_info = {}
        self.soup = None
        self.translations = {}
        self.remove_working_dir = True
        self.converters_dir = os.path.dirname(os.path.realpath(__file__))

        if not self.logger:
            self.logger = logging.getLogger()
            self.logger.setLevel(logging.DEBUG)
            ch = logging.StreamHandler()
            ch.setLevel(logging.DEBUG)
            formatter = logging.Formatter('%(levelname)s - %(message)s')
            ch.setFormatter(formatter)
            self.logger.addHandler(ch)

    def __del__(self):
        if self.remove_working_dir:
            shutil.rmtree(self.working_dir)

    def translate(self, key):
        if not self.translations:
            if self.lang_code not in LANGUAGE_FILES:
                self.logger.error('No locale file for {0}.'.format(self.lang_code))
                exit(1)
            locale_file = os.path.join(self.converters_dir, '..', 'locale', LANGUAGE_FILES[self.lang_code])
            if not os.path.isfile(locale_file):
                self.logger.error('No locale file found at {0} for {1}.'.format(locale_file, self.lang_code))
                exit(1)
            self.translations = load_json_object(locale_file)
        keys = key.split('.')
        t = self.translations
        for key in keys:
            t = t.get(key, None)
            if t is None:
                # handle the case where the self.translations doesn't have that (sub)key
                self.logger.error("No translation for `{0}`".format(key))
                exit(1)
                break
        return t

    def run(self):
        self.setup_dirs()
        self.setup_resource_files()
        self.file_id = '{0}_{1}_{2}'.format(self.main_resource.repo_name,
                                            '_{0}'.format(self.project_id) if self.project_id else '',
                                            self.main_resource.tag, self.main_resource.commit)
        self.setup_logging_to_file()
        self.setup_info()
        self.determine_if_regeneration_needed()
        self.generate_html()
        self.generate_pdf()

    def setup_dirs(self):
        if not self.working_dir:
            if 'WORKING_DIR' in os.environ:
                self.working_dir = os.environ['WORKING_DIR']
                self.logger.info('Using env var WORKING_DIR: {0}'.format(self.working_dir))
                self.remove_working_dir = False
            else:
                self.working_dir = tempfile.mkdtemp(prefix='{0}-'.format(self.main_resource.repo_name))
                self.remove_working_dir = True

        if not self.output_dir:
            if 'OUTPUT_DIR' in os.environ:
                self.output_dir = os.environ['OUTPUT_DIR']
                self.logger.info('Using env var OUTPUT_DIR: {0}'.format(self.output_dir))
            if not self.output_dir:
                self.output_dir = self.working_dir
                self.remove_working_dir = False

        self.html_dir = os.path.join(self.output_dir, 'html')

        self.save_dir = os.path.join(self.output_dir, '{0}_save'.format(self.file_id))
        if not os.path.isdir(self.save_dir):
            os.makedirs(self.save_dir)

        self.html_file = os.path.join(self.output_dir, '{0}.html'.format(self.file_id))
        self.pdf_file = os.path.join(self.output_dir, '{0}.pdf'.format(self.file_id))

        link_name = os.path.join(self.output_dir, 'converters')
        subprocess.call('ln -sf "{0}" "{1}"'.format(self.converters_dir, link_name), shell=True)

    def setup_logging_to_file(self):
        LOGGER.setLevel('INFO')  # Set to 'INFO' for debugging
        logger_handler = logging.FileHandler(os.path.join(self.output_dir, '{0}_logger.log'.format(self.file_id)))
        self.logger.addHandler(logger_handler)
        logger_handler = logging.FileHandler(os.path.join(self.output_dir, '{0}_weasyprint.log'.format(self.file_id)))
        LOGGER.addHandler(logger_handler)

    def setup_info(self):
        manifest = self.main_resource.get_manifest()
        self.title = manifest['dublin_core']['title']
        self.version = manifest['dublin_core']['version']
        if self.project_id:
            for project in manifest['projects']:
                if project.identifier == self.project_id:
                    self.project_title = project.title
            if self.project_title:
                self.logger.info('Project ID: {0}; Project Title: {1}'.format(self.project_id, self.project_title))
            else:
                self.logger.error('Project not found: {0}'.format(self.project_id))
                exit(1)

    def generate_html(self):
        if self.regenerate or not os.path.exists(self.html_file):
            self.logger.info('Creating HTML files for {0}...'.format(self.file_id))
            with open(os.path.join(self.converters_dir, 'templates/template.html')) as template_file:
                html_template = string.Template(template_file.read())
            html = html_template.safe_substitute(title='{0} - v{1}'.format(self.title, self.version))
            self.soup = BeautifulSoup(html, 'html.parser')
            self.soup.html.head.title.string = self.title
            if os.path.isfile(os.path.join(self.converters_dir, 'css/{0}.css'.format(self.resources.main.resource_name))):
                self.soup.html.head.append(BeautifulSoup('<link href="converters/css/{0}.css" rel="stylesheet">'.
                                                         format(self.resources.main.resource_name), 'html.parser'))
            self.logger.info('Generating cover page HTML...')
            cover_html = self.get_cover_html()
            self.soup.body.append(BeautifulSoup(cover_html, 'html.parser'))

            self.logger.info('Generating license page HTML...')
            license_html = self.get_license_html()
            license_element = BeautifulSoup(license_html, 'html.parser')
            self.soup.body.append(license_element)

            self.logger.info('Generating body HTML...')
            body_html = self.get_body_html()
            self.logger.info('Fixing links in body HTML...')
            body_html = self.fix_generic_links(body_html)
            body_html = self.fix_links(body_html)
            body_html = self.replace_rc_links(body_html)
            self.soup.body.append(BeautifulSoup(body_html, 'html.parser'))

            self.logger.info('Generating Contributors HTML...')
            contributors_html = self.get_contributors_html()
            self.soup.body.append(BeautifulSoup(contributors_html, 'html.parser'))

            self.download_all_images()

            self.logger.info('Generating TOC HTML...')
            toc_html = self.get_toc_html()
            license_element.insert_after(BeautifulSoup(toc_html, 'html.parser'))

            write_file(self.html_file, str(self.soup))

            self.save_resource_data()
            self.generate_bad_links_html()
            self.logger.info('Generated HTML file.')
        else:
            self.logger.info('HTML file {0} already there. Not generating. Use -r to force regeneration.'.
                             format(self.html_file))

    def generate_pdf(self):
        if self.regenerate or not os.path.exists(self.pdf_file):
            self.logger.info('Generating PDF file {0}...'.format(self.pdf_file))
            weasy = HTML(filename=self.html_file, base_url='file://{0}/'.format(self.output_dir))
            weasy.write_pdf(self.pdf_file)
            self.logger.info('Generated PDF file.')
            self.logger.info('PDF file located at {0}'.format(self.pdf_file))
            link_file = os.path.join(self.output_dir, format(self.file_id))
            subprocess.call('ln -sf "{0}" "{1}"'.format(self.pdf_file, link_file), shell=True)
        else:
            self.logger.info(
                'PDF file {0} already there. Not generating. Use -r to force regeneration.'.format(self.pdf_file))

    def generate_bad_links_html(self):
        bad_links = '<!DOCTYPE html><html lang="en-US"><head data-suburl=""><title>NON-MATCHING NOTES</title><meta charset="utf-8"></head><body><p>NON-MATCHING NOTES (i.e. not found in the frame text as written):</p><ul>'
        for cf in sorted(self.bad_links.keys()):
            bad_links += '<li><a href="html/{0}.html#obs-sn-{1}" title="See in the OBS SN Docs (HTML)" target="obs-sn-html">{1}</a><a href="https://git.door43.org/{6}/{2}_obs-sn/src/branch/{7}/content/{3}/{4}.md" style="text-decoration:none" target="obs-sn-git"><img src="http://www.myiconfinder.com/uploads/iconsets/16-16-65222a067a7152473c9cc51c05b85695-note.png" title="See OBS UTN note on DCS"></a><a href="https://git.door43.org/{6}/{2}_obs/src/branch/master/content/{3}.md" style="text-decoration:none" target="obs-git"><img src="https://cdn3.iconfinder.com/data/icons/linecons-free-vector-icons-pack/32/photo-16.png" title="See OBS story on DCS"></a>:<br/><i>{5}</i><br/><ul>'.format(
                self.file_id, cf, self.lang_code, cf.split('-')[0], cf.split('-')[1], self.bad_links[cf]['text'], self.owner, DEFAULT_TAG)
            for note in self.bad_links[cf]['notes']:
                for key in note.keys():
                    if note[key]:
                        bad_links += '<li><b><i>{0}</i></b><br/>{1} (QUOTE ISSUE)</li>'.format(key, note[key])
                    else:
                        bad_links += '<li><b><i>{0}</i></b></li>'.format(key)
            bad_links += '</ul></li>'
        bad_links += "</u></body></html>"
        save_file = os.path.join(self.output_dir, '{0}_bad_links.html'.format(self.file_id))
        write_file(save_file, bad_links)
        self.logger.info('BAD LINKS file can be found at {0}'.format(save_file))

    def setup_resource_files(self):
        for resource_name, resource in self.resources.items():
            resource.clone(self.working_dir)
            self.generation_info[resource.repo_name] = {'tag': resource.tag, 'commit': resource.commit}
            logo_path = os.path.join(self.html_dir, '{0}.png'.format(resource.resource_name))
            if not os.path.isfile(logo_path):
                command = 'curl -o "{0}" {1}'.\
                    format(logo_path, resource.get_logo_url())
                subprocess.call(command, shell=True)

    def determine_if_regeneration_needed(self):
        # check if any commit hashes have changed
        old_info = self.get_previous_generation_info()
        if not old_info:
            self.logger.info('Looks like this is a new commit of {0}. Generating PDF.'.format(self.file_id))
            self.regenerate = True
        else:
            for resource in self.generation_info:
                if resource in old_info and resource in self.generation_info \
                        and (old_info[resource]['tag'] != self.generation_info[resource]['tag']
                             or old_info[resource]['commit'] != self.generation_info[resource]['commit']):
                    self.logger.info('Resource {0} has changed: {1} => {2}, {3} => {4}. REGENERATING PDF.'.format(
                        resource, old_info[resource]['tag'], self.generation_info[resource]['tag'],
                        old_info[resource]['commit'], self.generation_info[resource]['commit']
                    ))
                    self.regenerate = True

    def save_resource_data(self):
        if not os.path.exists(self.save_dir):
            os.makedirs(self.save_dir)
        save_file = os.path.join(self.save_dir, '{0}_resource_data.json'.format(self.file_id))
        write_file(save_file, self.resource_data)
        save_file = os.path.join(self.save_dir, '{0}_references.json'.format(self.file_id))
        write_file(save_file, self.rc_references)
        save_file = os.path.join(self.save_dir, '{0}_bad_links.json'.format(self.file_id))
        write_file(save_file, self.bad_links)
        save_file = os.path.join(self.save_dir, '{0}_generation_info.json'.format(self.file_id))
        write_file(save_file, self.generation_info)

    def get_previous_generation_info(self):
        save_file = os.path.join(self.save_dir, '{0}_generation_info.json'.format(self.file_id))
        if os.path.isfile(save_file):
            return load_json_object(save_file)
        else:
            return {}

    def download_all_images(self):
        img_dir = os.path.join(self.html_dir, '{0}_images'.format(self.main_resource.repo_name))
        os.makedirs(img_dir, exist_ok=True)
        for img in self.soup.find_all('img'):
            if img['src'].startswith('http'):
                url = img['src']
                filename = re.search(r'/([\w_-]+[.](jpg|gif|png))$', url).group(1)
                img['src'] = 'html/{0}_images/{1}'.format(self.main_resource.repo_name, filename)
                filepath = os.path.join(img_dir, filename)
                if not os.path.exists(filepath):
                    with open(filepath, 'wb') as f:
                        response = requests.get(url)
                        f.write(response.content)

    @abstractmethod
    def get_body_html(self):
        return NotImplemented

    def get_toc_html(self):
        toc_html = '''
<article id="contents">
    <h1>{0}</h1>
'''.format(self.translate('table_of_contents'))
        current_level = 0
        count = 0
        for header in self.soup.find_all(re.compile(r'^h\d'), {'class': 'section-header'}):
            level = int(header.name[1])
            if level > current_level:
                for l in range(current_level, level):
                    toc_html += '<ul>\n<li>\n'
            elif level < current_level:
                for l in range(current_level, level, -1):
                        toc_html += '\n</li>\n</ul>\n'
            elif level == current_level:
                if current_level > 0:
                    toc_html += '\n</li>\n'
                toc_html += '\n<li>\n'
            if header.get('id'):
                link = '#{0}'.format(header.get('id'))
            if header.parent and header.parent.get('id'):
                link = '#{0}'.format(header.parent.get('id'))
            else:
                header_id = 'article-{0}'.format(count)
                count += 1
                header['id'] = header_id
                link = '#{0}'.format(header_id)
            toc_html += '<a href="{0}"><span>{1}</span></a>'.format(link, header.text)
            current_level = level
        for l in range(current_level, 0, -1):
            toc_html += '</li>\n</ul>\n'
        toc_html += '</article>'
        return toc_html

    def get_cover_html(self):
        project_title_html = ''
        version_title_html = ''
        if self.project_title:
            project_title_html = '<h2 id="cover-project">{0}</h2>'.format(self.project_title)
            version_title_html = '<h3 id="cover-version">{0} {1}</h3>'.format(self.translate('license.version'),
                                                                              self.version)
        else:
            version_title_html = '<h2 id="cover-version">{0} {1}</h2>'.format(self.translate('license.version'),
                                                                              self.version)
        cover_html = '''
<article id="main-cover" class="cover">
    <img src="html/{0}.png" alt="UTN"/>
    <h1 id="cover-title">{1}</h1>
    {2}
    {3}
</article>
'''.format(self.main_resource.resource_name, self.title, project_title_html, version_title_html)
        return cover_html

    def get_license_html(self):
        license_html = '''
<article id="license">
    <h1>{0}</h1>
'''.format(self.translate('license.copyrights_and_licensing'))
        for resource_name, resource in self.resources.items():
            manifest = resource.get_manifest()
            title = manifest['dublin_core']['title']
            version = manifest['dublin_core']['version']
            publisher = manifest['dublin_core']['publisher']
            issued = manifest['dublin_core']['issued']

            license_html += '''
    <div class="resource-info">
      <div class="resource-title"><strong>{0}</strong></div>
      <div class="resource-date"><strong>{1}:</strong> {2}</div>
      <div class="resource-version"><strong>{3}:</strong> {4}</div>
      <div class="resource-publisher"><strong>{5}:</strong> {6}</div>
    </div>
'''.format(title, self.translate('license.date'), issued, self.translate('license.version'), version,
           self.translate('license.published_by'), publisher)

        license_file = os.path.join(self.main_resource.repo_dir, 'LICENSE.md')
        license_html += markdown2.markdown_path(license_file)
        license_html += '</article>'
        return license_html

    def get_contributors_html(self):
        contributors_html = '<section id="contributors">'
        for idx, resource_name in enumerate(self.resources.keys()):
            resource = self.resources[resource_name]
            manifest = resource.get_manifest()
            contributors_html += '<div class="contributors-list">'
            if idx == 0:
                contributors_html += '<h1 class="section-header">Contributors</h1>'
            contributors_html += '<span class="h2">{0}</span>'.format(manifest['dublin_core']['title'])
            for contributor in manifest['dublin_core']['contributor']:
                contributors_html += '<div class="contributor">{0}</div>'.format(contributor)
            contributors_html += '</div>'
        contributors_html += '</section>'
        return contributors_html

    @staticmethod
    def highlight_text(text, note):
        parts = re.split(r"\s*…\s*|\s*\.\.\.\s*", note)
        processed_text = ''
        to_process_text = text
        for idx, part in enumerate(parts):
            split_pattern = re.escape(part)
            if '<span' in text:
                split_pattern = '({0})'.format(re.sub('(\\\\ )+', r'(\\s+|(\\s*</*span[^>]*>\\s*)+)', split_pattern))
            else:
                split_pattern = '({0})'.format(split_pattern)
            splits = re.split(split_pattern, to_process_text, 1)
            processed_text += splits[0]
            if len(splits) > 1:
                processed_text += '<span class="highlight{0}">{1}</span>'.format(' split' if len(parts) > 1 else '',
                                                                                 splits[1])
                if len(splits) > 2:
                    to_process_text = splits[-1]
        if to_process_text:
            processed_text += to_process_text
        return processed_text

    def highlight_text_with_frame(self, orig_text, frame_html, cf):
        ignore = []
        highlighted_text = orig_text
        phrases = []
        soup = BeautifulSoup(frame_html, 'html.parser')
        headers = soup.find_all('h4')
        for header in headers:
            phrases.append(header.text)
        phrases.sort(key=len, reverse=True)
        for phrase in phrases:
            new_highlighted_text = self.highlight_text(highlighted_text, phrase)
            if new_highlighted_text != highlighted_text:
                highlighted_text = new_highlighted_text
            elif phrase not in ignore:
                if cf not in self.bad_links:
                    self.bad_links[cf] = {
                        'text': orig_text,
                        'notes': []
                    }
                bad_note = {phrase: None}
                alt_notes = [
                    phrase.replace('‘', "'").replace('’', "'").replace('“', '"').replace('”', '"'),
                    phrase.replace("'", '’').replace('’', '‘', 1).replace('"', '”').replace('”', '“', 1),
                    phrase.replace('‘', "'").replace('’', "'").replace('“', '"').replace('”', '"'),
                    phrase.replace("'", '’').replace('’', '‘', 1).replace('"', '”').replace('”', '“', 1),
                    phrase.replace('“', '"').replace('”', '"'),
                    phrase.replace('"', '”').replace('”', '“', 1),
                    phrase.replace("'", '’').replace('’', '‘', 1),
                    phrase.replace("'", '’'),
                    phrase.replace('’', "'"),
                    phrase.replace('‘', "'")]
                for alt_note in alt_notes:
                    if orig_text != self.highlight_text(orig_text, alt_note):
                        bad_note[phrase] = alt_note
                        break
                self.bad_links[cf]['notes'].append(bad_note)
        return highlighted_text

    @staticmethod
    def increase_headers(text, increase_depth=1):
        if text:
            for num in range(5, 0, -1):
                text = re.sub(r'<h{0}>\s*(.+?)\s*</h{0}>'.format(num), r'<h{0}>\1</h{0}>'.format(num + increase_depth),
                              text, flags=re.MULTILINE)
        return text

    @staticmethod
    def decrease_headers(text, minimum_header=1, decrease=1):
        if text:
            for num in range(minimum_header, minimum_header + 10):
                text = re.sub(r'<h{0}>\s*(.+?)\s*</h{0}>'.format(num),
                              r'<h{0}>\1</h{0}>'.format(num - decrease if (num - decrease) <= 5 else 5), text,
                              flags=re.MULTILINE)
        return text

    @staticmethod
    def get_first_header(text):
        lines = text.split('\n')
        if len(lines):
            for line in lines:
                if re.match(r'<h1>', line):
                    return re.sub(r'<h1>(.*?)</h1>', r'\1', line)
            return lines[0]
        return "NO TITLE"

    def replace(self, m):
        before = m.group(1)
        rc = m.group(2)
        after = m.group(3)
        if rc not in self.resource_data:
            return m.group()
        info = self.resource_data[rc]
        if (before == '[[' and after == ']]') or (before == '(' and after == ')') or before == ' ' \
                or (before == '>' and after == '<'):
            return '<a href="{0}">{1}</a>'.format(info['link'], info['title'])
        if (before == '"' and after == '"') or (before == "'" and after == "'"):
            return info['link']
        self.logger.error("FOUND SOME MALFORMED RC LINKS: {0}".format(m.group()))
        return m.group()

    def replace_rc_links(self, html):
        # Change rc://... rc links to proper HTML links based on that links title and link to its article
        if self.lang_code != DEFAULT_LANG_CODE:
            html = re.sub('rc://en', 'rc://{0}'.format(self.lang_code), html, flags=re.IGNORECASE)
        joined = '|'.join(map(re.escape, self.resource_data.keys()))
        pattern = r'(\[\[|\(|["\']| |>|)\b(' + joined + r')\b(\]\]|\)|["\']|<|)(?!\]\)")'

        html = re.sub(pattern, self.replace, html, flags=re.IGNORECASE)
        # Remove other scripture reference not in this SN
        html = re.sub(r'<a[^>]+rc://[^>]+>([^>]+)</a>', r'\1', html, flags=re.IGNORECASE | re.MULTILINE)
        return html

    def fix_generic_links(self, html):
        # Change [[http.*]] to <a href="http\1">http\1</a>
        html = re.sub(r'\[\[http([^\]]+)\]\]', r'<a href="http\1">http\1</a>', html, flags=re.IGNORECASE)

        # convert URLs to links if not already
        html = re.sub(r'([^">])((http|https|ftp)://[A-Za-z0-9\/\?&_\.:=#-]+[A-Za-z0-9\/\?&_:=#-])',
                      r'\1<a href="\2">\2</a>', html, flags=re.IGNORECASE)

        # URLS wth just www at the start, no http
        html = re.sub(r'([^\/])(www\.[A-Za-z0-9\/\?&_\.:=#-]+[A-Za-z0-9\/\?&_:=#-])', r'\1<a href="http://\2">\2</a>',
                      html, flags=re.IGNORECASE)

        return html

    def fix_links(self, html):
        # could be implemented by child class
        return html


def run_converter(resource_names: List[str], pdf_converter_class: Type[PdfConverter]):
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('-l', '--lang_code', dest='lang_codes', required=False, help='Language Code(s)',
                        action='append')
    parser.add_argument('-p', '--project_id', dest='project_ids', required=False, help='Project ID(s)', action='append')
    parser.add_argument('-w', '--working', dest='working_dir', default=False, required=False, help='Working Directory')
    parser.add_argument('-o', '--output', dest='output_dir', default=False, required=False, help='Output Directory')
    parser.add_argument('--owner', dest='owner', default=DEFAULT_OWNER, required=False, help='Owner')
    parser.add_argument('-r', '--regenerate', dest='regenerate', action='store_true',
                        help='Regenerate PDF even if exists')
    for resource_name in resource_names:
        parser.add_argument('--{0}-tag'.format(resource_name), dest=resource_name, default=DEFAULT_TAG, required=False)

    args = parser.parse_args(sys.argv[1:])
    lang_codes = args.lang_codes
    project_ids = args.project_ids
    working_dir = args.working_dir
    output_dir = args.output_dir
    owner = args.owner
    regenerate = args.regenerate
    if not lang_codes:
        lang_codes = [DEFAULT_LANG_CODE]
    if not project_ids:
        project_ids = [None]

    resources = Resources()
    for lang_code in lang_codes:
        for project_id in project_ids:
            for resource_name in resource_names:
                repo_name = '{0}_{1}'.format(lang_code, resource_name)
                tag = getattr(args, resource_name)
                resource = Resource(resource_name=resource_name, repo_name=repo_name, tag=tag, owner=owner, logo='obs')
                resources[resource_name] = resource
            converter = pdf_converter_class(resources=resources, project_id=project_id, working_dir=working_dir,
                                            output_dir=output_dir, lang_code=lang_code, regenerate=regenerate)
            converter.logger.info('Starting PDF Converter for {0}_{1}{2}...'.
                                  format(resources.main.repo_name, resources.main.tag,
                                         '_{0}'.format(project_id) if project_id else ''))
            converter.run()
